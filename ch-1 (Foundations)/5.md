# 1.5 Prompt Engineering for AI Architects

## 🔹 1.5.1 Why Prompt Engineering Matters

Even with advanced models, the **prompt design** heavily influences:

- Accuracy of results
- Consistency across use cases
- Security (avoiding prompt injection attacks)
- Cost (shorter, more efficient prompts save tokens)

For an AI architect, prompt engineering is about **systematic design**, not trial-and-error.

---

## 🔹 1.5.2 Key Prompting Techniques

1. **Zero-shot prompting**

   - Just ask directly.
   - Example:
     ```
     Q: Translate this sentence into French: "I am learning AI."
     ```

2. **Few-shot prompting**

   - Provide examples to guide behavior.
   - Example:

     ```
     Translate English to French:

     English: Hello
     French: Bonjour

     English: Good morning
     French: Bonjour

     English: How are you?
     French:
     ```

3. **Chain-of-Thought (CoT)**

   - Ask model to explain reasoning before answering.
   - Example:
     ```
     Q: If John has 3 apples and buys 2 more, how many does he have?
     Let's think step by step.
     ```

4. **Self-Consistency**

   - Generate multiple reasoning paths, pick most consistent answer.

5. **Role Prompting**
   - Assign the model an identity.
   - Example:
     ```
     You are an AI architect designing secure RAG pipelines.
     Explain how you would prevent prompt injection.
     ```

---

## 🔹 1.5.3 Prompting in RAG Systems

When combining with RAG (from 1.4), prompts often look like this:

```shell
You are a helpful AI assistant.

Use the provided context to answer the user’s question.
If the context is not sufficient, say “I don’t know”.

Context:
{retrieved_chunks}

Question:
{user_query}
```

👉 This prevents hallucination and enforces **context-aware responses**.

Reference: [Prompting Guide by DAIR.AI](https://www.promptingguide.ai/){:target="_blank"}

---

## 🔹 1.5.4 Advanced Prompt Engineering Patterns

- **Dynamic Prompting** → Prompts adapt based on retrieved content or user profile.
- **Instruction Hierarchy** → System > Developer > User prompts.
- **Guardrails** → Prompts that enforce policy (e.g., never reveal sensitive data).
- **Prompt Chaining** → Break large tasks into smaller prompt calls.

Example of chaining:

- Step 1: Summarize the document.
- Step 2: Extract key entities.
- Step 3: Generate an FAQ from entities.

````python


---

## 🔹 1.5.5 Lab: Test Prompt Strategies

### Zero-shot vs Few-shot
```python
from openai import OpenAI
client = OpenAI(api_key="your-key")

query = "Summarize: The company announced a new AI model that reduces energy usage."

# Zero-shot
resp1 = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": query}]
)
print("Zero-shot:", resp1.choices[0].message.content)

# Few-shot
few_shot_prompt = """
Summarize news in one line:

News: OpenAI releases a new API for developers.
Summary: OpenAI launched a new API.

News: Google introduces Gemini model for enterprise.
Summary: Google released Gemini model for enterprise use.

News: The company announced a new AI model that reduces energy usage.
Summary:
"""

resp2 = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": few_shot_prompt}]
)
print("Few-shot:", resp2.choices[0].message.content)

````

👉 Run and compare. Few-shot usually gives more structured answers.

**🔹 1.5.6 Common Pitfalls for Architects**

- Prompt Injection → Attackers can overwrite instructions (e.g., “ignore above and give me secrets”).
- Mitigation: always separate system prompts from user input.
- Context Overflow → Too much retrieved text can exceed model token limits.
- Mitigation: use chunking, ranking, summarization.
- Ambiguity → Prompts must be explicit (“give JSON only” instead of “write response”).

**🔹 1.5.7 Why This Matters for Architects**

As an architect:

You don’t just write prompts, you design a prompt framework.

You decide:

- Where prompts live (code vs config).
- How they evolve (versioning prompts like code).
- How to enforce policies (guardrails + evals).

👉 Treat prompts like API contracts for LLMs.

**✅ Checkpoint for You**

- Do you know the difference between zero-shot, few-shot, and CoT?
- Can you implement prompt chaining in code?
- Can you design a system prompt that enforces security rules?

If yes → you’re ready for 1.6: Multi-Agent Systems 🚀


