# 1.6 Practical Tools for Agentic Workflows

This section covers **hands-on frameworks and libraries** to start building and experimenting with AI agents.  
We will explore three major tools: **LangChain**, **AutoGen**, and **Semantic Kernel**.

---

## 1.6.1 LangChain

[LangChain](https://www.langchain.com/) is a framework designed for **composable AI applications**.  
It helps developers link **LLMs, data sources, and tools** together into workflows.

### Key Concepts:

- **LLM Wrappers** – unified interface to OpenAI, Anthropic, Hugging Face, etc.
- **Chains** – sequences of calls (LLMs, APIs, functions).
- **Agents** – LLMs with decision-making power to choose which tool/step to run.
- **Memory** – retain context across calls (short-term, long-term).

### Example: Using LangChain with OpenAI

```python
from langchain_openai import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

llm = OpenAI(model="gpt-4", temperature=0)
prompt = PromptTemplate.from_template("Translate this English text to French: {text}")

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run({"text": "Hello, how are you?"})
print(result)
```

---

## 1.6.2 AutoGen

[AutoGen](https://github.com/microsoft/autogen) (by Microsoft Research) focuses on **multi-agent conversations**.  
It allows AI agents to collaborate with each other and with humans.

### Key Concepts:

- **AssistantAgent** – represents an LLM assistant.
- **UserProxyAgent** – simulates a human user or external system.
- **Multi-Agent Chat** – agents communicate to solve problems.
- **Tool Integration** – agents can call external APIs, run code, or query data.

---

## 1.6.3 Semantic Kernel

[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/) (by Microsoft) is an SDK for **AI orchestration**.  
It helps combine **LLMs, embeddings, and planners** with existing enterprise systems.

### Key Concepts:

- **Plugins** – wrap skills like summarization, Q&A, search.
- **Planners** – decompose complex tasks into sub-steps.
- **Connectors** – integrate with Azure, databases, APIs.

### Example: Semantic Kernel Plugin Usage

```csharp
using Microsoft.SemanticKernel;

var kernel = Kernel.Builder.Build();
await kernel.ImportPluginFromPromptDirectoryAsync("SummarizePlugin");

string summary = await kernel.RunAsync("AI is transforming software engineering.");
Console.WriteLine(summary);
```

---

## 1.6.4 Comparing Frameworks

| Feature           | LangChain             | AutoGen                   | Semantic Kernel          |
| ----------------- | --------------------- | ------------------------- | ------------------------ |
| Main Focus        | Tool chaining         | Multi-agent collaboration | Enterprise orchestration |
| Ease of Use       | Medium                | Easy/Medium               | Medium/Hard              |
| Production Ready? | Yes, but evolving     | Experimental              | Microsoft-backed stable  |
| Good For          | Prototyping pipelines | AI teamwork simulations   | Enterprise apps          |

---

## 1.6.5 Example: Two-Agent System in AutoGen

```python
from autogen import AssistantAgent, UserProxyAgent

# Define agents
assistant = AssistantAgent(name="assistant", llm_config={"model": "gpt-4"})
user_proxy = UserProxyAgent(name="user_proxy", human_input_mode="NEVER")

# Simple conversation
assistant.initiate_chat(user_proxy, message="Summarize recent AI research trends.")
```

**Explanation:**

- The `assistant` is the **AI worker agent**.
- The `user_proxy` is a **simulated user agent**.
- Together, they form a **two-agent system** for collaboration.
- This is a foundation for **multi-agent workflows**.

---

## 1.6.6 Extending with Tools

Agents can call APIs, query databases, or run local code.  
In **LangChain**, this is done by registering tools.

```python
from langchain.agents import initialize_agent, Tool
from langchain_openai import OpenAI

def get_weather(location: str) -> str:
    return f"The weather in {location} is Sunny."

llm = OpenAI(model="gpt-4")
tools = [Tool(name="WeatherAPI", func=get_weather, description="Fetches weather info.")]

agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)
agent.run("What’s the weather in Amsterdam?")
```

---

## 1.6.7 Suggested Labs

1. **LangChain Lab:**  
   Build an AI agent that answers questions using Wikipedia search.

2. **AutoGen Lab:**  
   Create two agents – one that asks coding questions and another that solves them.

3. **Semantic Kernel Lab:**  
   Connect SK to a document store (PDFs) and build a summarization assistant.

---

## 1.6.8 Summary

- **LangChain** = composable pipelines and tools.
- **AutoGen** = multi-agent collaboration.
- **Semantic Kernel** = enterprise orchestration.
- Hands-on experimentation will build intuition about **agent architectures**.

**Next Step:** Combine these frameworks with **MCP (Model Context Protocol)** in the next section.
