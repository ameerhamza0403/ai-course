# Chapter 2: AI System Design & Architecture Foundations

## 2.7 Security and Compliance in AI Systems

Designing AI systems isn’t only about performance and scalability — security and compliance are equally critical. As organizations deploy AI into sensitive environments (finance, healthcare, government), the ability to **secure models, data pipelines, and infrastructure** while ensuring **legal and ethical compliance** is essential.

---

### 2.7.1 Core Security Principles for AI Systems

- **Data Confidentiality**  
  Encrypt data in transit (TLS/SSL) and at rest (AES-256). Protect sensitive features (like PII).

- **Model Integrity**  
  Prevent model poisoning, adversarial attacks, or backdoor insertion. Validate training data provenance.

- **Access Control**  
  Implement strict IAM (Identity & Access Management). Follow principle of least privilege.

- **Auditability**  
  Ensure traceability of model decisions, data usage, and access logs.

---

### 2.7.2 Threats Specific to AI

1. **Data Poisoning Attacks**

   - Maliciously injected training data corrupts model behavior.
   - Example: Spam filters trained with mislabeled emails.

2. **Adversarial Examples**

   - Small perturbations in input trick model into misclassification.
   - Example: Stop sign altered to be misread by self-driving cars.

3. **Model Extraction / Stealing**

   - Attackers query models and reconstruct them externally.

4. **Inference Attacks**
   - Sensitive training data inferred from model predictions.

---

### 2.7.3 Compliance Considerations

- **GDPR (General Data Protection Regulation)**

  - Right to explanation for automated decisions.
  - Data minimization & purpose limitation.

- **HIPAA (Health Data Protection)**

  - For AI in healthcare, ensure anonymization & PHI handling compliance.

- **SOC 2 & ISO 27001**
  - For enterprise-grade ML pipelines, security certifications ensure trust.

---

### 2.7.4 Best Practices

1. **Secure Data Pipelines**

   - Use encrypted storage, signed data, hashing for integrity.

2. **Robust Model Deployment**

   - Container signing & scanning.
   - Use admission controllers in Kubernetes.

3. **Continuous Monitoring**

   - Drift detection (distribution shifts).
   - Anomaly detection for unusual model behavior.

4. **Zero-Trust Architecture**
   - Assume no implicit trust within networks.
   - Apply MFA (multi-factor authentication) and micro-segmentation.

---

### 2.7.5 Case Study – Financial Fraud Detection AI

- **Problem:** A bank deployed a fraud detection model but faced adversarial attempts (fraudsters bypassing by injecting synthetic data).
- **Mitigation:**
  - Shifted to adversarial training (training model on perturbed data).
  - Implemented **real-time drift detection** to catch unusual transaction patterns.
  - Built **audit dashboards** to trace high-value false negatives.
- **Outcome:** Reduced false negatives by **27%** while remaining GDPR-compliant.

---

## 2.7.6 Security Flow Diagrams

To better understand how security layers integrate into AI system design, we visualize two key flows: **Threat Modeling for AI Pipelines** and **Zero-Trust Workflow**.

---

### Diagram 1: AI Pipeline Threat Modeling

```text
              +-------------------+
              |   Data Sources    |
              +-------------------+
                       |
                       v
        +----------------------------+
        |   Data Ingestion Layer     |
        | - Secure APIs              |
        | - Data validation checks   |
        +----------------------------+
                       |
                       v
        +----------------------------+
        |   Data Storage             |
        | - Encrypted (at rest)      |
        | - Access control policies  |
        +----------------------------+
                       |
                       v
        +----------------------------+
        |   Model Training           |
        | - Poisoning detection      |
        | - Adversarial defense      |
        +----------------------------+
                       |
                       v
        +----------------------------+
        |   Model Serving            |
        | - API rate limiting        |
        | - Model watermarking       |
        +----------------------------+
                       |
                       v
        +----------------------------+
        |   Monitoring & Logging     |
        | - Drift detection          |
        | - Security auditing        |
        +----------------------------+

```

**Diagram 2: Zero-Trust Workflow for AI Systems**

        +-------------------------------+
        |   User / Service Identity     |
        | - Strong IAM policies         |
        | - Multi-factor authentication |
        +-------------------------------+
                       |
                       v
        +-------------------------------+
        |   Policy Enforcement Layer    |
        | - Access token validation     |
        | - Role-based restrictions     |
        +-------------------------------+
                       |
                       v
        +-------------------------------+
        |   Secure AI Service Gateway   |
        | - Request inspection          |
        | - TLS termination             |
        +-------------------------------+
                       |
                       v
        +-------------------------------+
        |   AI Model Endpoint           |
        | - Adversarial input filter    |
        | - Query rate control          |
        +-------------------------------+
                       |
                       v
        +-------------------------------+
        |   Continuous Monitoring       |
        | - Anomaly detection           |
        | - Compliance logging          |
        +-------------------------------+
